name: seed
on:
  workflow_dispatch:

jobs:
  seed_models_cache:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install minimal deps
        shell: pwsh
        run: |
          python -m pip install --upgrade pip
          pip install "huggingface_hub==0.24.*" "transformers==4.57.*" "sentence-transformers==3.*"
          pip install torch --index-url https://download.pytorch.org/whl/cpu

      - name: Warm models into models_cache/
        shell: pwsh
        env:
          HF_HUB_OFFLINE: 0
          TRANSFORMERS_OFFLINE: 0
          SRO_CACHE_DIR: models_cache
          HF_HOME: models_cache
          SENTENCE_TRANSFORMERS_HOME: models_cache
          TRANSFORMERS_CACHE: models_cache
          HF_HUB_CACHE: models_cache/hub
          HF_HUB_DISABLE_TELEMETRY: 1
        run: |
          python -m scripts.warm_models
          if (-not (Test-Path "models_cache/hub/models--sentence-transformers--all-MiniLM-L6-v2")) { Write-Error "ST snapshot missing"; exit 2 }
          if (-not (Get-ChildItem models_cache/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/*/config.json -ErrorAction SilentlyContinue)) { Write-Error "ST config.json missing in cache"; exit 3 }
          Write-Host "Cache size:"; Get-ChildItem -Recurse models_cache | Measure-Object -Property Length -Sum

      - name: Save cache (models_cache)
        uses: actions/cache/save@v4
        with:
          path: models_cache
          key: models-cache-win-v2
